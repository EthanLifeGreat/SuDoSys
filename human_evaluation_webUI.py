# Copyright (c) Alibaba Cloud.
#
# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.

"""A simple web interactive chat demo based on gradio."""
import json

from utils.ssid import generate_ssid
from argparse import ArgumentParser
import gradio as gr
from openai import OpenAI
import random
import pandas as pd
from utils.backend_main import create

model_name_list = ["Qwen2-7B-Instruct", "PsyChat-0724-chat", "CPsyCoun-0724-chat", "SoDuSys"]

# Set OpenAI's API key and API base to use vLLM's API server.
openai_api_key = "EMPTY"
openai_api_base = "http://10.10.1.211:8008/v1"
client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

# read metric.txt into metrics string
with open("data/metrics.txt", "r", encoding="utf-8") as f:
    metric_str = f.read()

# read metric.txt into metrics string
with open("data/client_portraits_cpc.json", 'r', encoding='utf-8') as file:
    client_portraits_cpc = json.load(file)

# read metric.txt into metrics string
with open("data/client_portrait_intro.txt", "r", encoding="utf-8") as f:
    cp_intro_str = f.read()


df_headers = ["AIå’¨è¯¢å¸ˆ", "é€»è¾‘æ€§", "ä¸“ä¸šæ€§", "åŒç†å¿ƒ", "çœŸå®æ€§"]
default_dataframe_value = [
    ["å’¨è¯¢å¸ˆ1", 0, 0, 0, 0],
    ["å’¨è¯¢å¸ˆ2", 0, 0, 0, 0],
    ["å’¨è¯¢å¸ˆ3", 0, 0, 0, 0],
    ["å’¨è¯¢å¸ˆ4", 0, 0, 0, 0],
]
default_dataframe_value = pd.DataFrame(default_dataframe_value, columns=df_headers)


def _get_args():
    parser = ArgumentParser()
    parser.add_argument("--share", action="store_true", default=False,
                        help="Create a publicly shareable link for the interface.")
    parser.add_argument("--inbrowser", action="store_true", default=False,
                        help="Automatically launch the interface in a new tab on the default browser.")
    parser.add_argument("--server-port", type=int, default=8000,
                        help="Demo server port.")
    parser.add_argument("--server-name", type=str, default="0.0.0.0",
                        help="Demo server name.")

    args = parser.parse_args()
    return args


def _gc():
    import gc
    gc.collect()


def _launch_demo(args):
    def predict(_query, _chatbot, _task_history, _model_id, _sds_cache, _scores):
        print(f"User: {_query}")
        _chatbot.append((_query, ""))

        conversation = []
        for query_h, response_h in _task_history:
            conversation.append({'role': 'user', 'content': query_h})
            conversation.append({'role': 'assistant', 'content': response_h})
        conversation.append({'role': 'user', 'content': _query})

        model_name = model_name_list[_scores["model_mapping"][_model_id-1]-1]
        print(model_name)
        if len(_sds_cache) > 1:
            cache = _sds_cache[-1]
        else:
            cache = None
        response, tmp = create(model_name, conversation, cache)
        _sds_cache.append(tmp)
        _chatbot[-1] = (_query, response)
        yield _chatbot

        # print(f"History: {_task_history}")
        _task_history.append((_query, response))
        # print(f"Qwen2-Instruct: {response}")

    def reset_user_input():
        return gr.update(value="")

    def reset_state(_chatbot, _task_history, _sds_cache):
        _task_history.clear()
        _chatbot.clear()
        _gc()
        _sds_cache = {"stage": 1}
        return _chatbot

    def update_dataframe(_scores):
        # è¿™é‡Œå‡è®¾ scores ä¸­åŒ…å«äº†æ¨¡å‹çš„åˆ†æ•°
        data = [
            ["å’¨è¯¢å¸ˆ1", _scores["model_1"][0], _scores["model_1"][1], _scores["model_1"][2], _scores["model_1"][3]],
            ["å’¨è¯¢å¸ˆ2", _scores["model_2"][0], _scores["model_2"][1], _scores["model_2"][2], _scores["model_2"][3]],
            ["å’¨è¯¢å¸ˆ3", _scores["model_3"][0], _scores["model_3"][1], _scores["model_3"][2], _scores["model_3"][3]],
            ["å’¨è¯¢å¸ˆ4", _scores["model_4"][0], _scores["model_4"][1], _scores["model_4"][2], _scores["model_4"][3]],
        ]
        _df = pd.DataFrame(data, columns=["AIå’¨è¯¢å¸ˆ", "é€»è¾‘æ€§", "ä¸“ä¸šæ€§", "åŒç†å¿ƒ", "çœŸå®æ€§"])
        return _df

    js_func = """
    function refresh() {
        const url = new URL(window.location);
        if (url.searchParams.get('__theme') !== 'dark') {
            url.searchParams.set('__theme', 'dark');
            window.location.href = url.href;
        }
    }
    """

    def process_form(selection1, selection2, selection3, selection4, state, _model_id):
        if selection1 and selection2 and selection3 and selection4:
            # ç”Ÿæˆç»“æœ
            out = f"å’¨è¯¢å¸ˆ{_model_id}åˆ†æ•°ä¿å­˜æˆåŠŸï¼\né€»è¾‘æ€§: {selection1}\nä¸“ä¸šæ€§: {selection2}" \
                  f"\nåŒç†å¿ƒ: {selection3}\nçœŸå®æ€§: {selection4}\n\n# æ‰€æœ‰è¯„åˆ†ä¿å­˜å®Œæˆåè¯·åœ¨é¡µé¢æœ€ä¸‹é¢è¡¨æ ¼å¤„ç‚¹å‡»åˆ·æ–°åæäº¤ï¼"
            result = [selection1, selection2, selection3, selection4]
            # æ›´æ–°çŠ¶æ€
            state[f"model_{_model_id}"] = result
            # state[str(time.time())] = result
            # print(state)
            return out
        else:
            return "å­˜åœ¨ç¼ºçœå€¼ï¼Œè¯·æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ–¹é¢å·²å¡«å†™ã€‚"

    def get_random_cp():
        num_client_portraits = len(client_portraits_cpc)
        _id = random.randint(0, num_client_portraits-1)

        return json.dumps(client_portraits_cpc[_id], indent=4, separators=(',', ': '), ensure_ascii=False)

    def generate_random_array():
        random_list = random.sample(range(1, 5), 4)  # ç”Ÿæˆ1åˆ°4çš„éšæœºæ’åˆ—
        for _i in random_list:
            print(model_name_list[_i - 1])
        # print(random_list)
        return random_list

    # ç¤ºä¾‹æäº¤æŒ‰é’®çš„å¤„ç†å‡½æ•°ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ å…·ä½“å®ç°ï¼‰
    def on_whole_submit(_scores, _df):
        pd_df = pd.DataFrame(_df)
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ 0 å€¼
        contains_zero = (pd_df == 0).any().any()

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ None å€¼
        contains_none = pd_df.isnull().any().any()
        if contains_zero or contains_none:
            return "å­˜åœ¨ç¼ºçœå€¼ï¼Œè¯·æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ¨¡å‹ç»“æœå·²æäº¤ã€‚"
        print(_scores, _df)
        for _model_id in range(1, 5):
            model_name = model_name_list[_scores["model_mapping"][_model_id-1]-1]
            # pd_dfä¸­åä¸º"AIå’¨è¯¢å¸ˆ"çš„åˆ—ä¸­çš„è¡Œå·ä¸º_model_idè¡Œçš„å€¼ä¿®æ”¹ä¸ºmodel_name
            pd_df.loc[_model_id-1, "AIå’¨è¯¢å¸ˆ"] = model_name
        # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
        ssid = generate_ssid()
        pd_df.to_csv(f"./results/result_{ssid}.csv", index=False)

        return "å…¨éƒ¨è¯„ä»·ç»“æœå·²æäº¤ï¼æ„Ÿè°¢æ‚¨å‚ä¸æœ¬æ¬¡æµ‹è¯„ï¼ğŸŒ¹ğŸŒ¹ğŸŒ¹"

    with gr.Blocks(title='å¿ƒç†å’¨è¯¢èŠå¤©æœºå™¨äººæµ‹è¯„', js=js_func) as demo:

        gr.Markdown(
            """<p align="center"><img src="https://www.siat.ac.cn/images/logo2016.png?v1.0" 
            style="height: 60px"/><p>""")
        gr.Markdown("""<center><font size=8>å¿ƒç†å’¨è¯¢èŠå¤©æœºå™¨äººæµ‹è¯„</center>""")
        gr.Markdown(
            """\
<left><font size=3>æ¬¢è¿æ‚¨æ¥åˆ°æˆ‘ä»¬çš„å¿ƒç†å’¨è¯¢èŠå¤©æœºå™¨äººæµ‹è¯„é¡µé¢ã€‚\
åœ¨è¿™ä¸ªé¡µé¢ä¸­ï¼Œæ‚¨å°†è¯„ä¼°4åAIå¿ƒç†å’¨è¯¢å¸ˆå¯¹åŒä¸€ä½å®¢æˆ·çš„æä¾›çš„å¿ƒç†å’¨è¯¢å¯¹è¯å†…å®¹ï¼Œå¹¶ä¸ºæ¯ä¸ªAIå’¨è¯¢å¸ˆçš„ä»¥ä¸‹å››ä¸ªæ–¹é¢è¿›è¡Œè¯„åˆ†ï¼ˆä»1ã€2ã€3ã€4ã€5åˆ†ä¸­é€‰æ‹©ä¸€ä¸ªï¼Œ5åˆ†è¡¨ç¤ºæœ€å¥½ï¼Œ1åˆ†è¡¨ç¤ºæœ€å·®ï¼‰ã€‚ä»¥ä¸‹æ˜¯å‚è€ƒè¯„ä»·æ ‡å‡†å’Œäººè®¾ã€‚
</left>""")
        model_mapping = gr.State(generate_random_array())

        scores = gr.State({"model_1": [0, 0, 0, 0], "model_2": [0, 0, 0, 0], "model_3": [0, 0, 0, 0], "model_4": [0, 0, 0, 0],
                           "model_mapping": model_mapping.value})

        with gr.Row():
            gr.Textbox(value=metric_str, interactive=False, label="å‚è€ƒè¯„ä»·æ ‡å‡†")
            with gr.Column():
                gr.Textbox(value=cp_intro_str, interactive=False, label="å‚è€ƒå’¨è¯¢è€…ç”»åƒ")
                client_portraits_tb = gr.Textbox(value="", interactive=False, label="ç”»åƒ")
                cp_renew_button = gr.Button("ğŸ‘€æŸ¥çœ‹ä¸‹ä¸€ä¸ªç”»åƒ")

        cp_renew_button.click(fn=get_random_cp, outputs=client_portraits_tb)
        sds_cache = gr.State([])


        for r in range(1, 3):
            with gr.Row():
                for c in range(1, 3):
                    with gr.Column():
                        i = (r - 1) * 2 + c
                        gr.Markdown(f"\n# ä»¥ä¸‹æ˜¯æ‚¨ä¸AIå’¨è¯¢å¸ˆ{i}çš„å¯¹è¯æ¡†ï¼š")
                        chatbot = gr.Chatbot(label=f'AIå’¨è¯¢å¸ˆ{i}', elem_classes="control-height", show_copy_button=True)
                        query = gr.Textbox(lines=2, label='Input')
                        task_history = gr.State([])

                        model_id = gr.State(i)

                        with gr.Row():
                            empty_btn = gr.Button("ğŸ§¹ Clear History (æ¸…é™¤å†å²)")
                            submit_btn = gr.Button("ğŸš€ Submit (å‘é€)")

                        submit_btn.click(predict, [query, chatbot, task_history, model_id, sds_cache, scores],
                                         [chatbot], show_progress="full")
                        submit_btn.click(reset_user_input, [], [query])
                        empty_btn.click(reset_state, [chatbot, task_history, sds_cache], outputs=[chatbot],
                                        show_progress="full")

                        gr.Markdown(f"## è¯·å¯¹AIå’¨è¯¢å¸ˆ{i}çš„ä»¥ä¸‹4ä¸ªæ–¹é¢è¿›è¡Œè¯„åˆ†ï¼š")
                        with gr.Row():
                            logic_score = gr.Radio(["1", "2", "3", "4", "5"], label="é€»è¾‘æ€§")
                            prof_score = gr.Radio(["1", "2", "3", "4", "5"], label="ä¸“ä¸šæ€§")

                        with gr.Row():
                            empathy_score = gr.Radio(["1", "2", "3", "4", "5"], label="åŒç†å¿ƒ")
                            authentic_score = gr.Radio(["1", "2", "3", "4", "5"], label="çœŸå®æ€§")

                        score_submit_btn = gr.Button("ä¿å­˜")
                        output = gr.Textbox(label="ä¿å­˜ç»“æœ")

                        score_submit_btn.click(
                            fn=process_form,
                            inputs=[logic_score, prof_score, empathy_score, authentic_score, scores, model_id],
                            outputs=output
                        )
                        # score_submit_btn.click(
                        #     update_dataframe,
                        #     inputs=scores,
                        #     outputs=df
                        # )
        gr.Markdown("\n# ")
        gr.Markdown("\n\n# è¯·æ›´æ–°å¹¶æŸ¥çœ‹å·²ä¿å­˜åˆ†æ•°å¹¶åœ¨æœ€åè¿›è¡Œæ•´ä½“åˆ†æ•°æäº¤")
        df = gr.Dataframe(
            value=default_dataframe_value,
            row_count=(4, "fixed"),
            col_count=(5, "fixed"),
        )

        with gr.Row():
            score_status_submit_btn = gr.Button("åˆ·æ–°å·²è¯„ä¼°åˆ†æ•°")
            whole_submit_btn = gr.Button("æäº¤æ•´ä¸ªè¯„ä»·ç»“æœ")
        output = gr.Textbox(label="æäº¤ç»“æœ")
        # ç»‘å®šæŒ‰é’®ç‚¹å‡»äº‹ä»¶
        score_status_submit_btn.click(
            update_dataframe,
            inputs=scores,
            outputs=df
        )
        whole_submit_btn.click(
            on_whole_submit,
            inputs=[scores, df],
            outputs=output
        )
    demo.queue().launch(
        share=args.share,
        inbrowser=args.inbrowser,
        server_port=args.server_port,
        server_name=args.server_name,
    )


def main():
    args = _get_args()

    _launch_demo(args)


if __name__ == '__main__':
    main()
